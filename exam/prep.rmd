# SW2 - Deskiptive Statistik
## Mittel, Varianz, Standardabweichung, Quar/ntile, Boxplot
### Mittel, Median
```{r}
arr <- c(1,4,3,6,3,6,4)
mean(arr)
median(arr)
```

### Varianz Standardabweichung
```{r}
arr <- c(1,4,3,6,3,6,4)
var(arr)
sd(arr)
```
### Quantil (wherever) / Quartil (25%, 75%)
```{r}
arr <- c(1,4,3,6,3,6,4)
quantile(arr, p=0.25, type=2)
quantile(arr, p=0.75, type=2)
quantile(arr, p = c(0.25, 0.75), type=2)
quantile(arr, p = seq(from = .2, to = 1, by = .2), type = 2)
IQR(arr, type=2)
```

# SW3 - Histogramm, zweidimensionale deskriptive Statistik, Histogramm

- Create a Histogram, a plot and draw a regression line

# SW4 - Korrelation, Wahrscheinlichkeitsmodelle

```{r}
arr <- c(1,4,3,6,3,6,4)
arr2 <- c(1,7,3,8,3,6,4)
cor(arr2, arr)
```

4.5.r & 4.md sehr viele Beispiele zu Wahrscheinlichkeiten
-> interfsect, Unabhaengigkeit, ...

# SW5 - Zufallsvariable, Wahrscheinlichkeitsverteilung

```{r}
arr <- c(1,4,3,6,3,6,4)
p<-1/6
E_X <- sum(arr*p)
var_X <- sum( arr - E_X)^2 * p
sd_X <- sqrt(var_X)
sd_X
sd(arr)
```

Aufsteigende Wahrscheinlichkeiten
```{r}
# hoechstens 8 fragen richtig = 0.711
k.1.correct <- 0.2
k.up.8 <- 0.711
k.up.9 <- 0.939
k.up.10 <- 0.969
k.up.11 <- 0.982
k.up.12 <- 0.989
k.up.13 <- 0.992
k.up.14 <- 0.999
k.up.15 <- 1

# a) hoechstens 13 Aufgaben richtig
k.up.13
# b) mindestens 10 Aufgaben richtig: 1- hoechstens 9
1 - k.up.9
# c) genau 15 richtig: hoechstens 15 - hoechstens 14
k.up.15 - k.up.14
# d)zwischen 9 und 12 Aufgaben richtig: 9, 10, 11 oder 12 richtig: hoechstens 12 - hoechstens 8
k.up.12 - k.up.8
```

# SW6 - bedingte Wahrscheinlichkeiten

```{r}
# b) gegebene Wahrscheinlichkeiten
p.k <- 0.01 # dass man krank ist
p.t.k <- 0.98 # k|t, positiv getestet wenn krank
p.t.not.k <- 0.03 # wenn gesund, test ist positiv

# c) P(notK) -> wahrscheinlichkeit gesund zu sein
p.not.k <- 0.99 # 1-p.k

# d) Wahrscheinlichkeit eines positiven Ergebnis
# p.k -> p.t.k & p.not.t.k (krank -> positiv & negativ)
# p.not.k -> p.t.not.k & p.not.t.not.k (gesund -> positiv & negativ)

p.t <- (p.t.k * p.k) + (p.t.not.k * p.not.k)
p.t # 0.0395 = 3,95% der getesteten sind positiv

# e) positiver Test heisst auch wirklich krank
# wenn ich positiv bin, bin ich auch wirklich krank
# Bayes: P(K|T) = (K intersect T) / P(T) = (P(T|K)*P(K)) / P(T)
p.k.t <- (p.t.k * p.k) / p.t
p.k.t # 0.2481 <- 25% aller positiven sind auch wirklich krank

# f) negative getestet ist gesund P(notK|notT)
p.not.t.not.k <- 1 - p.t.not.k
p.not.t <- 1 - p.t
p.not.k.not.t <- (p.not.t.not.k * p.not.k) / p.not.t
p.not.k.not.t # 0.9997918 <- ist test negativ, ist das sehr sicher = gesund
# positiv sagt nicht viel aus, negativ schon

```

# SW7 - Normalverteilung

X~N(µ, σ2 )

Normalverteilt mit t µ = 100 und σ = 15:
X ∼ N (100, 15^2 )

P(X>130), wobei X ∼ N (100, 15^2 )

Pnorm berechnet jetzt P(X<=130):
```{r}
pnorm(q=130, mean=100, sd=15
```

Also: 1- P(X<=130) = P(X>130): -> wie viel Prozent?
```{r}
1 - pnorm(q = 130, mean = 100, sd = 15)
```

Welches *Intervall* hat 95% um den Mittelwert  µ = 100? Links je 2.5% weg:
```{r}
qnorm(p = c(0.025, 0.975), mean = 100, sd = 15)
```
P(85 <= X <=115) -> wie viel Prozent?
```{r}
pnorm(q = 115, mean = 100, sd = 15) - pnorm(85, 100, 15)
```

# SW8 - Gesetz der grossen Zahlen, zentraler Grenzwerzusatz

Normalverteilung, mehrmals

S50 ∼ N (50 · µ, 50 · σ^2x)  = N (75, 4.5)
Finde P(Sn<= 80):
```{r}
pnorm(q = 80, mean = 50 * 1.5, sd = sqrt(50) * 0.3)
```
sd=20, n=16, mean=100
N ( 100, 20^2/ 16)  = N (100, 25)
Finde P(X16 <=104):
```{r}
pnorm(q = 104, mean = 100, sd = 20/sqrt(16)
```
Finde P(98<=X16<=104), n=16, sd=20:
```{r}
pnorm(q = 104, mean = 100, sd = 20/sqrt(16)) - pnorm(98, 100, 20/sqrt(16))
pnorm(q = 2200, mean = 2000, sd = 8000/sqrt(1000)) - pnorm(2100, 2000, 8000/sqrt(1000))
```

# SW9 - Hypothesentest, z-Test, t-Test

## z-Test - SD bekannt & Normalverteilung

Wahrscheinlichkeit, dass 80 stimmt bei realem Mittel 97,88.
Groesse muss >0.025 sein, sonst Nullhypothese verwerfen
```{r}
pnorm(q = 79.98, mean = 80, sd = 0.02/sqrt(6)
```
Grenze Verwerfungsbereich:
```{r}
qnorm(p = 0.05, mean = 180, sd = 10/sqrt(8))
```

p-Wert fuer P(X<171.54):
```{r}
pnorm(q = 171.54, mean = 180, sd = 10/sqrt(8))
```

## t-Test - SD unbekannt, Verteilung aendern

Verwerfungsbereich mit qt(), p-Wert mit pt()

Beides zusammen: (alternative="less")
```{r}
t.test(arr, mu=E_X)
```

# SW10 - Vertrauensintervall, Zweistichprobentest, Wilcoxon-Test

## Wilcoxon - nicht-Normalverteilt

p < alpha -> H0 verwerfen
```{r}
wilcox.test(arr, mu=80, alternative = “two-sided”)
#95% Vertrauensintervall
wilcox.test(x, y, alternative = "two.sided", mu = 0, paired = FALSE, conf.level = 0.95)
```

## t.Test

Gepaart:

```{r}
t.test(nachher, vorher, alternative = "two.sided", mu = 0, paired = TRUE, conf.level = 0.95)
```

Ungepaart
```{r}
t.test(x, y, alternative = "two.sided", mu = 0, paired = FALSE, conf.level = 0.95)
```

# SW11 - lineare regression

Streudiagramm:
```{r}
plot(Verkauf ~ TV, col = "darkcyan", xlab = "TV", ylab = "Verkauf")
```

Zusammenhang schaetzen:
Y ≈ β0 + β1X1 + β2X2 + . . . + βpXp

- Intercept: y-Achsenabschnitt
- TV: Steigung: Y ≈ 7.03 + 0.0475X -> pro 1000 mehr Werbeausgaben, gibt es 47.5 mal mehr Verkaeufe
- keine Werbung, 7.03 Verkauf

```{r}
lm(Verkauf ~ TV)
```

Graphisch:
```{r}
plot(TV, Verkauf, col = "darkcyan", xlab = "TV", ylab = "Verkauf", pch = 20) 
abline(lm(Verkauf ~ TV), col = "blue")
```

Vertrauensintervall der einzelnen Werte 95%:
```{r}
confint(lm(Verkauf ~ TV), level = 0.95)
```

- p-Wert: kleiner 0.05 -> H0=kein Zusammenhang verwerfen -> Zusamenhang
- R^2: Welche Anteil der Variablitaet in Y kann mit Modell
erklaert werden in %.
```{r}
cor(x,y)
summary(lm(y~x)$r.squared
var(y)
```

# SW12 - Multiple lineare Regression

Y = β0 + β1X1 + β2X2 + . . . + βpXp + ε

Nur Koeffizienten in der Gleichung:
```{r}
coef(lm(Einkommen ~ Ausbildung + Erfahrung))
```
Interpretation:

- keine Ausbildung & Erfahrung: Lohn=-50k (praktisch keinen Sinn)
- const Erfahrung, pro Ausbildungsjahr mehr += 5896.-
- const Ausbildung, pro Erfahrungsjahr mehr += 173.-


Alles:
```{r}
summary(lm(Einkommen ~ Ausbildung + Erfahrung))
```

Korrelationen zwischen Daten:
```{r}
cor(data.frame(TV, Radio, Zeitung, Verkauf))
```

```{r}
predict(lm(Verkauf ~ TV + Radio), interval = "confidence", data.frame(TV = 100, Radio = 20) )
```

Interaktionsterm:
medv = β0 + β1 · lstat + β2 · age + β12 · lstat*age
```{r}
lm(medv ~ lstat * age, data = Boston)
```

# SW 13 - Qualitative (erklaerende) Variablen

Streudiagramm, um Zusammenhaenge zu erkennen:
```{r}
pairs(~Balance + Age + Cards + Education + Income + Limit + Rating, data = Credit, pch = ".", col = "darkcyan")
```

```{r}
summary(lm(Sales ~ Price + Urban + US, data=Carseats))
# 13.04: wenn nicht Urban und nicht in US und Preis=0, dann werden 13 Kindersitze verkauft
# Price um 1 hoeher: -0.05 weniger Carseats verkauft
# wenn urban: 0.02 Kindersitze weniger verkauft: P hoch also zufaellig
# wenn in US: 1.2 Kindersitzer mehr verkauft

# Gleichungsform:
# urban: x2i = {1=Urban, 0=Land}
# US: x3i = {1 falls in USA, 0=not-USA}
#yi = b0 - Price*b1 - x2i*b2 + x3i*b3 + ei
# + b2 + b3 +ei -> urban in usa
# + b3 + ei: rural in USA
# + b2 + ei: urban nicht in USA
# ei: rural nicht in usa

# H0 verwerfen: fuer Price und US (p sehr klein)

# kleineres Modell mit nur passenden Praedikatioren:
summary(lm(Sales ~ Price + US, data=Carseats))
# US: x3i = {1 falls in USA, 0=not-USA}
#yi = b0 - Price*b1 - x2i*b2 + ei
# Zusammenhang ist gegeben, aber R^2: 0.23 -> sehr schlecht
# nur 23% der Variabilitaets kann mit Modell erklaert werden
```